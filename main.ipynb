{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Screenshot saved: screenshots/question_20250311_234352.png\n",
      "Extracted Question: Iravel Guide # ocreen Analyzer witn LOCai LLM\n",
      "\n",
      "This Python script captures a specific area of the screen, extracts text using OCR, and analyzes it\n",
      "\n",
      "i<?)\n",
      "\n",
      "SciSpace\n",
      "\n",
      "## . Features\n",
      "-— Captures a screen region (supports *x*primary and secondary monitors*x)\n",
      "- Extracts text using **Tesseract OCR**\n",
      "- Sends the text to a **local Llama 3 model** for analysis\n",
      "88 Explore GPTs - Outputs a *ksummary** or an *kanswer** (configurable)\n",
      "\n",
      "Al Language Tutors: L...\n",
      "\n",
      "## S€ Installation\n",
      "Today\n",
      "\n",
      "### 1. Install dependencies:\n",
      "Quiz Cheating Detection Me... ~**bash\n",
      "\n",
      "pip install -r requirements.txt\n",
      "Random Text Generation\n",
      "\n",
      "2. Ensure Tesseract OCR is installed on macOS:\n",
      "2 days ago\n",
      "\n",
      "Vrindavan Afternoon Activities bash O) Copy\n",
      "\n",
      "brew install tesseract\n",
      "\n",
      "3 days ago\n",
      "Property Restrictions Explai... 3. Run the script:\n",
      "Writing Women's Day Postc... bash © Copy\n",
      "\n",
      "Introduction Meetup Frangais .\n",
      "python main.py\n",
      "\n",
      "Dandruff Treatment Tips ;\n",
      "1: Configuration v\n",
      "AI Answer: Here is a summary of the text and an analysis:\n",
      "\n",
      "**Summary**\n",
      "\n",
      "The text describes a Python script called \"Iravel Guide\" that captures a region of the screen, extracts text using Optical Character Recognition (OCR), and analyzes it using a local Large Language Model (LLM). The script has several features, including support for multiple monitors, configurable output formats, and integration with a Tesseract OCR engine. The installation process involves installing dependencies using pip and ensuring Tesseract OCR is installed on macOS.\n",
      "\n",
      "**Analysis**\n",
      "\n",
      "The script appears to be designed for screen analysis tasks, such as:\n",
      "\n",
      "1. **Text extraction**: The script uses Tesseract OCR to extract text from a captured region of the screen.\n",
      "2. **Language analysis**: The extracted text is then sent to a local LLM (specifically, Llama 3) for analysis.\n",
      "3. **Output generation**: The script can produce either a summary or an answer based on the analysis, which is configurable.\n",
      "\n",
      "The script's features suggest that it may be used in various applications, such as:\n",
      "\n",
      "1. **Accessibility tools**: The script could be used to assist individuals with visual impairments by extracting and analyzing text from the screen.\n",
      "2. **Screen scraping**: The script could be used to extract data from web pages or other graphical user interfaces (GUIs).\n",
      "3. **Text analysis**: The script could be used for various text analysis tasks, such as sentiment analysis, entity recognition, or information extraction.\n",
      "\n",
      "Overall, the Iravel Guide script appears to be a powerful tool for screen analysis and text processing tasks.\n",
      "Results saved: results/response_20250311_234352.txt\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "import cv2\n",
    "import ollama\n",
    "import os\n",
    "import mss\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "# Ensure required directories exist\n",
    "os.makedirs(\"screenshots\", exist_ok=True)\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "# Set Tesseract OCR path\n",
    "pytesseract.pytesseract.tesseract_cmd = \"/opt/homebrew/bin/tesseract\"\n",
    "\n",
    "# Select the monitor (0 is primary, 1 is secondary)\n",
    "monitor_index = 0  # Change this to 1 for the secondary screen\n",
    "\n",
    "# Define coordinates for the question area\n",
    "x, y, width, height = 0, 200, 1600, 600  # Adjust as per screen layout\n",
    "\n",
    "with mss.mss() as sct:\n",
    "    monitors = sct.monitors  # Get all available monitors\n",
    "    if len(monitors) > monitor_index:\n",
    "        monitor = monitors[monitor_index]\n",
    "\n",
    "        # Capture the screen area\n",
    "        screenshot = sct.grab({\n",
    "            \"top\": monitor[\"top\"] + y,\n",
    "            \"left\": monitor[\"left\"] + x,\n",
    "            \"width\": width,\n",
    "            \"height\": height\n",
    "        })\n",
    "\n",
    "        # Convert screenshot to OpenCV format\n",
    "        image = np.array(screenshot)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGRA2BGR)\n",
    "\n",
    "        # Generate timestamp for unique file names\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "        # Save the screenshot\n",
    "        screenshot_path = f\"screenshots/question_{timestamp}.png\"\n",
    "        cv2.imwrite(screenshot_path, image)\n",
    "        print(f\"Screenshot saved: {screenshot_path}\")\n",
    "\n",
    "        # Convert to grayscale for OCR\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Extract question text using OCR\n",
    "        extracted_text = pytesseract.image_to_string(gray).strip()\n",
    "        print(\"Extracted Question:\", extracted_text)\n",
    "\n",
    "        # Query local Llama 3 model via Ollama\n",
    "        response = ollama.chat(\n",
    "            model=\"llama3.1:latest\",\n",
    "            messages=[{\"role\": \"user\", \"content\": f\"Analyse the text and give summary: {extracted_text}\"}]\n",
    "            # If you want to answer it to question that is on screen\n",
    "            # messages=[{\"role\": \"user\", \"content\": f\"Answer this quiz question concisely: {extracted_text}\"}]\n",
    "        )\n",
    "\n",
    "        # Extract AI-generated answer\n",
    "        answer = response['message']['content']\n",
    "        print(\"AI Answer:\", answer)\n",
    "\n",
    "        # Save extracted text and AI response\n",
    "        result_path = f\"results/response_{timestamp}.txt\"\n",
    "        with open(result_path, \"w\") as file:\n",
    "            file.write(f\"Extracted Text:\\n{extracted_text}\\n\\n\")\n",
    "            file.write(f\"AI Answer:\\n{answer}\\n\")\n",
    "        print(f\"Results saved: {result_path}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Monitor {monitor_index} not found. Available monitors: {len(monitors) - 1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
